# -*- coding: utf-8 -*-
"""DCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13JUgMdYxdLkftBwKf8aWVmZxt_HUpAOb
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import tensorflow as tf  
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
import numpy as np

cudnn.benchmark = True
print("GPU: " + str(torch.cuda.is_available()))

import tensorflow as tf
from tensorflow.keras.datasets import cifar10

# Load the CIFAR100 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print(len(x_train))
print(len(x_test))

# Convert pixel values to float data type
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

data = []
data.extend(x_train)
data.extend(x_test)
data_min = np.min(data, axis=(1,2), keepdims=True)
data_max = np.max(data, axis=(1,2), keepdims=True)

scaled_data = (data - data_min) / (data_max - data_min)

#push normalized data back to x_train and x_test
x_train = scaled_data[:len(x_train)]
x_test = scaled_data[len(x_train):]

# make labels categorical
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# make a convolutional neural network
# Define the CNN model

model = Sequential()

# Add the first convolutional layer
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3), padding = 'same'))

# Add a second convolutional layer
model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding = 'same'))

# Add a max pooling layer
model.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))

# Add a third convolutional layer
model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding = 'same'))

# Add a fourth convolutional layer
model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding = 'same'))

# Add a max pooling layer
model.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))

# Add a fifth convolutional layer
model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding = 'same'))

# Add a sixth convolutional layer
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding = 'same'))

# Add a max pooling layer
model.add(MaxPooling2D(pool_size=(2,2), padding = 'same'))

# Flatten the output layer
model.add(Flatten())

# Add a fully connected layer with 128 hidden units and a ReLU activation function
model.add(Dense(512, activation='relu'))

# Add a dropout layer for regularization
model.add(Dropout(0.8))

# Add a fully connected layer with 128 hidden units and a ReLU activation function
model.add(Dense(500, activation='relu'))

# Add a dropout layer for regularization
model.add(Dropout(0.8))

# Add the output layer with 10 nodes (one for each class) and a softmax activation function
model.add(Dense(num_classes, activation='softmax'))

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

batch_size = 1000
# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#go to github and use a simple resnet/alexnet as a benchmark  

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=100,
          verbose=1,
          learning_rate=0.001,
          validation_data=(x_test, y_test),
          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)])
model.summary()

pred_train= model.predict(x_train)
scores = model.evaluate(x_train, y_train, verbose=0)
print('Accuracy on training data: {} \n Error on training data: {}'.format(scores[1], 1 - scores[1]))   
 
pred_test= model.predict(x_test)
scores2 = model.evaluate(x_test, y_test, verbose=0)
print('Accuracy on test data: {} \n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))